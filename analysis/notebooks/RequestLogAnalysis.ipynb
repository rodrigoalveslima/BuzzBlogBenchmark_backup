{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Log Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities\n",
    "- Display a summary of requests and their performance metrics.\n",
    "\n",
    "## Input\n",
    "Log files are read from a directory in `../data`. This directory is assumed to have the following structure:\n",
    "```\n",
    "logs/\n",
    "  [node-1]/\n",
    "    loadgen.tar.gz\n",
    "  ...\n",
    "  [node-n]/\n",
    "    loadgen.tar.gz\n",
    "```\n",
    "A tarball `loadgen.tar.gz` contains a request log file named `loadgen.log`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERAL\n",
    "# Name of the directory in `../data`\n",
    "EXPERIMENT_DIRNAME = \"BuzzBlogBenchmark_2021-10-10-18-35-22\"\n",
    "# Ramp up duration (in sec)\n",
    "RAMP_UP_DURATION = 60\n",
    "# Ramp down duration (in sec)\n",
    "RAMP_DOWN_DURATION = 60\n",
    "\n",
    "########## LATENCY\n",
    "# Max expected value\n",
    "MAX_LATENCY_IN_S = 10\n",
    "# Bin size\n",
    "LATENCY_BIN_IN_MS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import tarfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constants\n",
    "REQUEST_LOG_PATTERN = r\"^\\[(\\d+\\-\\d+\\-\\d+ \\d+:\\d+:\\d+.\\d+)\\] (.+) (.+) (\\d+) - latency=(\\d+.\\d+)$\"\n",
    "URL_PATTERN = r\"^http://[\\w\\.]+:\\d+/{path}/?\\??{qs}$\"\n",
    "REQUEST_TO_TYPE = {\n",
    "    (URL_PATTERN.format(path=\"account/\\d+\", qs=\"\"), \"GET\"): \"retrieve_account\",\n",
    "    (URL_PATTERN.format(path=\"account\", qs=\"\"), \"POST\"): \"create_account\",\n",
    "    (URL_PATTERN.format(path=\"account/\\d+\", qs=\"\"), \"PUT\"): \"update_account\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"followee_id=\\d+\"), \"GET\"): \"retrieve_account_followers\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"follower_id=\\d+\"), \"GET\"): \"retrieve_account_followees\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"\"), \"POST\"): \"follow_account\",\n",
    "    (URL_PATTERN.format(path=\"follow/\\d+\", qs=\"\"), \"DELETE\"): \"delete_follow\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"account_id=\\d+\"), \"GET\"): \"retrieve_account_likes\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"post_id=\\d+\"), \"GET\"): \"retrieve_post_likes\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"\"), \"POST\"): \"like_post\",\n",
    "    (URL_PATTERN.format(path=\"like/\\d+\", qs=\"\"), \"DELETE\"): \"delete_like\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"\"), \"GET\"): \"retrieve_recent_posts\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"author_id=\\d+\"), \"GET\"): \"retrieve_account_posts\",\n",
    "    (URL_PATTERN.format(path=\"post/\\d+\", qs=\"\"), \"GET\"): \"retrieve_post\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"\"), \"POST\"): \"create_post\",\n",
    "    (URL_PATTERN.format(path=\"post/\\d+\", qs=\"\"), \"DELETE\"): \"delete_post\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs\n",
    "requests = {\"timestamp\": [], \"method\": [], \"url\": [], \"status_code\": [], \"latency\": []}\n",
    "node_names = os.listdir(os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\"))\n",
    "for node_name in node_names:\n",
    "  node_min_timestamp = None\n",
    "  tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name, \"loadgen.tar.gz\")\n",
    "  if os.path.exists(tarball_path):\n",
    "    with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "      for filename in tar.getnames():\n",
    "        if filename.endswith(\"loadgen.log\"):\n",
    "          with tar.extractfile(filename) as requests_log_file:\n",
    "            for log in requests_log_file:\n",
    "              timestamp, method, url, status_code, latency = re.match(REQUEST_LOG_PATTERN, log.decode(\"utf-8\")).groups()\n",
    "              url = re.sub(\"limit=\\d+&?\", \"\", url)\n",
    "              url = re.sub(\"offset=\\d+&?\", \"\", url)\n",
    "              url = re.sub(\"request_id=[a-zA-Z0-9]+&?\", \"\", url)\n",
    "              url = re.sub(\"&$\", \"\", url)\n",
    "              url = re.sub(\"\\?$\", \"\", url)\n",
    "              timestamp = datetime.datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "              if node_min_timestamp is None:\n",
    "                node_min_timestamp = timestamp\n",
    "              requests[\"timestamp\"].append((timestamp - node_min_timestamp).total_seconds())\n",
    "              requests[\"method\"].append(method)\n",
    "              requests[\"url\"].append(url)\n",
    "              requests[\"status_code\"].append(int(status_code))\n",
    "              requests[\"latency\"].append(float(latency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "requests = pd.DataFrame.from_dict(requests)\n",
    "requests.sort_values(by=\"timestamp\", ascending=True, inplace=True)\n",
    "requests[\"status\"] = requests.apply(lambda r: \"successful\" if r[\"status_code\"] == 200 else \"failed\", axis=1)\n",
    "requests[\"window\"] = requests.apply(lambda r: int(r[\"timestamp\"]), axis=1)\n",
    "requests[\"type\"] = requests.apply(\n",
    "    lambda r: [request_type for ((pattern, method), request_type) in REQUEST_TO_TYPE.items()\n",
    "    if method == r[\"method\"] and re.match(pattern, r[\"url\"])][0], axis=1)\n",
    "requests[\"rw\"] = requests.apply(lambda r: \"read\" if r[\"method\"] == \"GET\" else \"write\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status of Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.gca()\n",
    "df = requests.groupby([\"status\"]).count()[\"method\"]\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"Number of successful/failed requests\", xlabel=\"\", ylabel=\"\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.gca()\n",
    "df = requests[requests[\"status\"] == \"failed\"].groupby([\"status_code\"]).count()[\"method\"]\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"HTTP status code of failed requests\", xlabel=\"\", ylabel=\"\", legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.gca()\n",
    "df = requests.groupby([\"rw\"]).count()[\"method\"]\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"Number of read/write requests\", xlabel=\"\", ylabel=\"\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "df = requests.groupby([\"type\", \"status\"]).count()[\"method\"].unstack().fillna(0)\n",
    "df.plot(ax=ax, kind=\"bar\", stacked=True, title=\"Number of requests of each type\", xlabel=\"\", ylabel=\"Requests (count)\",\n",
    "        color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Latency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca(xlabel=\"Latency (seconds)\", ylabel=\"Requests (count)\")\n",
    "ax.grid(alpha=0.75)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S))\n",
    "ax.set_ylim((0, 10000))\n",
    "ax.set_xticks(range(0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S + 1, (1000 // LATENCY_BIN_IN_MS)))\n",
    "ax.set_xticklabels([str(s) for s in range(MAX_LATENCY_IN_S + 1)])\n",
    "df = requests[requests[\"status\"] == \"successful\"]\n",
    "df = df[(df[\"timestamp\"] >= RAMP_UP_DURATION) & (df[\"timestamp\"] <= requests[\"timestamp\"].max() - RAMP_DOWN_DURATION)]\n",
    "df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "df[\"latency_bin\"].plot(ax=ax, kind=\"hist\",\n",
    "    title=\"Latency Distribution of Successful Requests Excluding Ramping Periods\",\n",
    "    bins=range((1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 24))\n",
    "for (i, (request_type, _)) in enumerate(requests.groupby([\"type\"])):\n",
    "  ax = fig.add_subplot(4, 4, i + 1)\n",
    "  ax.grid(alpha=0.75)\n",
    "  ax.set_yscale(\"log\")\n",
    "  ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S))\n",
    "  ax.set_ylim((0, 10000))\n",
    "  ax.set_xticks(range(0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S + 1, (1000 // LATENCY_BIN_IN_MS)))\n",
    "  ax.set_xticklabels([str(s) for s in range(MAX_LATENCY_IN_S + 1)])\n",
    "  df = requests[(requests[\"status\"] == \"successful\") & (requests[\"type\"] == request_type)]\n",
    "  df = df[(df[\"timestamp\"] >= RAMP_UP_DURATION) & (df[\"timestamp\"] <= requests[\"timestamp\"].max() - RAMP_DOWN_DURATION)]\n",
    "  df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "  df[\"latency_bin\"].plot(ax=ax, kind=\"hist\", title=request_type, xlabel=\"Latency (seconds)\", ylabel=\"Requests (count)\",\n",
    "      bins=range((1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.set_xlim((0, int(requests[\"timestamp\"].max())))\n",
    "ax.set_ylim((0, 10))\n",
    "ax.axvline(x=RAMP_UP_DURATION, ls=\"--\", color=\"green\")\n",
    "ax.axvline(x=requests[\"timestamp\"].max() - RAMP_DOWN_DURATION, ls=\"--\", color=\"green\")\n",
    "df = requests[requests[\"status\"] == \"successful\"]\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "df[\"latency\"].plot(ax=ax, kind=\"line\", title=\"Latency of Successful Requests\", xlabel=\"Time (seconds)\",\n",
    "    ylabel=\"Latency (seconds)\", color=\"purple\", grid=True, xticks=range(0, int(requests[\"timestamp\"].max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 24))\n",
    "for (i, (request_type, _)) in enumerate(requests.groupby([\"type\"])):\n",
    "  ax = fig.add_subplot(4, 4, i + 1)\n",
    "  ax.grid(alpha=0.75)\n",
    "  ax.set_xlim((0, int(requests[\"timestamp\"].max())))\n",
    "  ax.set_ylim((0, 10))\n",
    "  ax.axvline(x=RAMP_UP_DURATION, ls=\"--\", color=\"green\")\n",
    "  ax.axvline(x=requests[\"timestamp\"].max() - RAMP_DOWN_DURATION, ls=\"--\", color=\"green\")\n",
    "  df = requests[(requests[\"status\"] == \"successful\") & (requests[\"type\"] == request_type)]\n",
    "  df.set_index(\"timestamp\", inplace=True)\n",
    "  df[\"latency\"].plot(ax=ax, kind=\"line\", title=request_type, xlabel=\"Time (seconds)\",\n",
    "      ylabel=\"Latency (seconds)\", color=\"purple\", grid=True, xticks=range(0, int(requests[\"timestamp\"].max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.axvline(x=RAMP_UP_DURATION, ls=\"--\", color=\"green\")\n",
    "ax.axvline(x=requests[\"timestamp\"].max() - RAMP_DOWN_DURATION, ls=\"--\", color=\"green\")\n",
    "df = requests.groupby([\"window\", \"status\"])[\"window\"].count().unstack().fillna(0)\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "df.plot(ax=ax, kind=\"line\", title=\"Throughput (requests per second)\", xlabel=\"Time (seconds)\",\n",
    "        ylabel=\"Requests (count)\", color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True, grid=True,\n",
    "        xticks=range(0, int(df.index.max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of requests\")\n",
    "print(\"  Total:       %7d\" % requests.shape[0])\n",
    "print(\"  Status\")\n",
    "print(\"    Failed:    %7d (%9.5f%%)\" % (requests[requests[\"status\"] == \"failed\"][\"status\"].count(),\n",
    "    (requests[requests[\"status\"] == \"failed\"][\"status\"].count() / requests.shape[0]) * 100))\n",
    "print(\"    Succesful: %7d (%9.5f%%)\" % (requests[requests[\"status\"] == \"successful\"][\"status\"].count(),\n",
    "    (requests[requests[\"status\"] == \"successful\"][\"status\"].count() / requests.shape[0]) * 100))\n",
    "print(\"  Type\")\n",
    "print(\"    Read:      %7d (%9.5f%%)\" % (requests[requests[\"rw\"] == \"read\"][\"rw\"].count(),\n",
    "    (requests[requests[\"rw\"] == \"read\"][\"rw\"].count() / requests.shape[0]) * 100))\n",
    "print(\"    Write:     %7d (%9.5f%%)\" % (requests[requests[\"rw\"] == \"write\"][\"rw\"].count(),\n",
    "    (requests[requests[\"rw\"] == \"write\"][\"rw\"].count() / requests.shape[0]) * 100))\n",
    "print(\"Experiment duration (s)\")\n",
    "print(\"  Total:       %7.3f\" % requests[\"timestamp\"].max())\n",
    "print(\"Latency (ms)\")\n",
    "print(\"  P99:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.99) * 1000))\n",
    "print(\"  P95:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.95) * 1000))\n",
    "print(\"  P50:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.50) * 1000))\n",
    "print(\"  Avg:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].mean() * 1000))\n",
    "print(\"  Std:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].std() * 1000))\n",
    "print(\"Throughput (req/s)\")\n",
    "print(\"  P99:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"window\"].max()) + 1), fill_value=0).quantile(0.99))\n",
    "print(\"  P95:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"window\"].max()) + 1), fill_value=0).quantile(0.95))\n",
    "print(\"  P50:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"window\"].max()) + 1), fill_value=0).quantile(0.50))\n",
    "print(\"  Avg:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"window\"].max()) + 1), fill_value=0).mean())\n",
    "print(\"  Std:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"window\"].max()) + 1), fill_value=0).std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
