{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collectl Log Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities\n",
    "- Plot CPU utilization graphs.\n",
    "- Plot memory utilization graphs.\n",
    "- Plot disk I/O utilization graphs.\n",
    "\n",
    "## Input\n",
    "Log files are read from a directory in `../data`. This directory is assumed to have the following structure:\n",
    "```\n",
    "logs/\n",
    "  [node-1]/\n",
    "    collectl.tar.gz\n",
    "  ...\n",
    "  [node-n]/\n",
    "    collectl.tar.gz\n",
    "```\n",
    "A tarball `collectl.tar.gz` contains log files. The log file extension identifies the type of resource monitored:\n",
    "- `.cpu.gz`: CPU monitoring log file.\n",
    "- `.numa.gz`: memory monitoring log file.\n",
    "- `.dsk.gz`: disk I/O monitoring log file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERAL\n",
    "# Name of the directory in `../data`\n",
    "EXPERIMENT_DIRNAME = \"BuzzBlogBenchmark_2021-10-10-18-35-22\"\n",
    "\n",
    "########## CPU\n",
    "# Fine-grained window size (in ms)\n",
    "COLLECTL_CPU_FG_WINDOW_SIZE = 50\n",
    "# Aggregation function\n",
    "COLLECTL_CPU_AGGREGATION_FUNC = \"max\"\n",
    "# Analyzed metric (options: \"user\", \"nice\", \"system\", \"wait\", \"irq\", \"soft\",\n",
    "# \"steal\", \"idle\", \"total\", \"guest\", \"guest_n\", \"intrpt\")\n",
    "COLLECTL_CPU_METRIC = \"total\"\n",
    "\n",
    "########## Memory\n",
    "# Fine-grained window size (in ms)\n",
    "COLLECTL_MEM_FG_WINDOW_SIZE = 50\n",
    "# Aggregation function\n",
    "COLLECTL_MEM_AGGREGATION_FUNC = \"min\"\n",
    "# Analyzed metric (options: \"used\", \"free\", \"slab\", \"mapped\", \"anon\", \"anonh\", \"inactive\", \"hits\")\n",
    "COLLECTL_MEM_METRIC = \"free\"\n",
    "\n",
    "########## Disk I/O\n",
    "# Fine-grained window size (in ms)\n",
    "COLLECTL_DSK_FG_WINDOW_SIZE = 50\n",
    "# Aggregation function\n",
    "COLLECTL_DSK_AGGREGATION_FUNC = \"max\"\n",
    "# Analyzed metric (options: \"reads\", \"rmerge\", \"rkbytes\", \"waitr\", \"writes\", \"wmerge\", \"wkbytes\", \"waitw\", \"request\",\n",
    "# \"quelen\", \"wait\", \"svctim\", \"util\")\n",
    "COLLECTL_DSK_METRIC = \"quelen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "node_names = os.listdir(os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs\n",
    "CPU_METRICS = [\"user\", \"nice\", \"system\", \"wait\", \"irq\", \"soft\", \"steal\", \"idle\", \"total\", \"guest\", \"guest_n\", \"intrpt\"]\n",
    "cpu = {\"node_name\": [], \"core_no\": [], \"timestamp\": [], \"metric\": [], \"value\": []}\n",
    "for node_name in node_names:\n",
    "    tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name, \"collectl.tar.gz\")\n",
    "    with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "        for filename in tar.getnames():\n",
    "            if filename.endswith(\".cpu.gz\"):\n",
    "                with gzip.open(tar.extractfile(filename), \"rt\") as cpu_log_file:\n",
    "                    for log in cpu_log_file:\n",
    "                        if log[0] == '#':\n",
    "                            # Skip comments.\n",
    "                            continue\n",
    "                        log_entry = log.split()\n",
    "                        timestamp = datetime.datetime.strptime(\" \".join(log_entry[:2]), \"%Y%m%d %H:%M:%S.%f\")\n",
    "                        for core_no in range((len(log_entry) - 2) // len(CPU_METRICS)):\n",
    "                            for (i, metric) in enumerate(CPU_METRICS):\n",
    "                                cpu[\"node_name\"].append(node_name)\n",
    "                                cpu[\"core_no\"].append(core_no)\n",
    "                                cpu[\"timestamp\"].append(timestamp)\n",
    "                                cpu[\"metric\"].append(metric)\n",
    "                                cpu[\"value\"].append(float(log_entry[i + 2 + core_no * len(CPU_METRICS)]))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "cpu = pd.DataFrame.from_dict(cpu)\n",
    "min_timestamp = cpu[\"timestamp\"].min()\n",
    "cpu[\"time\"] = cpu.apply(lambda r: (r[\"timestamp\"] - min_timestamp).total_seconds(), axis=1)\n",
    "cpu[\"window\"] = cpu.apply(lambda r: int(r[\"time\"]), axis=1)\n",
    "cpu[\"fg_window\"] = cpu.apply(lambda r: int(r[\"time\"] * 1000) // COLLECTL_CPU_FG_WINDOW_SIZE, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CPU utilization of each node (1-second window)\n",
    "fig = plt.figure(figsize=(12, len(node_names) * 6))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = cpu[(cpu[\"node_name\"] == node_name) & (cpu[\"metric\"] == COLLECTL_CPU_METRIC)]\n",
    "    df = df.groupby([\"window\", \"core_no\"])[\"value\"].agg(COLLECTL_CPU_AGGREGATION_FUNC)\n",
    "    df = df.reindex([(i, j) for i in range(cpu[\"window\"].max() + 1) for j in range(cpu[\"core_no\"].max() + 1)],\n",
    "        fill_value=0)\n",
    "    df = df.unstack()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((0, df.index.max()))\n",
    "    ax.set_ylim((0, df.values.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\", title=\"%s - CPU Utilization (1-second window)\" % node_name, xlabel=\"Time (seconds)\",\n",
    "        ylabel=\"%s(%s) (%%)\" % (COLLECTL_CPU_AGGREGATION_FUNC, COLLECTL_CPU_METRIC), grid=True, legend=False,\n",
    "        xticks=range(0, df.index.max() + 1, 60), yticks=range(0, 101, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CPU utilization of each node (fine-grained window)\n",
    "fig = plt.figure(figsize=(12, len(node_names) * 6))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = cpu[(cpu[\"node_name\"] == node_name) & (cpu[\"metric\"] == COLLECTL_CPU_METRIC)]\n",
    "    df = df.groupby([\"fg_window\", \"core_no\"])[\"value\"].agg(COLLECTL_CPU_AGGREGATION_FUNC)\n",
    "    df = df.reindex([(i, j) for i in range(cpu[\"fg_window\"].max() + 1) for j in range(cpu[\"core_no\"].max() + 1)],\n",
    "        fill_value=0)\n",
    "    df = df.unstack()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((0, df.index.max()))\n",
    "    ax.set_ylim((0, df.values.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\", title=\"%s - CPU Utilization (%s-ms window)\" % (node_name, COLLECTL_CPU_FG_WINDOW_SIZE),\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"%s(%s) (%%)\" % (COLLECTL_CPU_AGGREGATION_FUNC, COLLECTL_CPU_METRIC),\n",
    "        grid=True, legend=False, yticks=range(0, 101, 10),\n",
    "        xticks=range(0, df.index.max() + 1, 60 * (1000 // COLLECTL_CPU_FG_WINDOW_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs\n",
    "MEM_METRICS = [\"used\", \"free\", \"slab\", \"mapped\", \"anon\", \"anonh\", \"inactive\", \"hits\"]\n",
    "mem = {\"node_name\": [], \"numa_node\": [], \"timestamp\": [], \"metric\": [], \"value\": []}\n",
    "for node_name in node_names:\n",
    "    tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name, \"collectl.tar.gz\")\n",
    "    with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "        for filename in tar.getnames():\n",
    "            if filename.endswith(\".numa.gz\"):\n",
    "                with gzip.open(tar.extractfile(filename), \"rt\") as mem_log_file:\n",
    "                    for log in mem_log_file:\n",
    "                        if log[0] == '#':\n",
    "                            # Skip comments.\n",
    "                            continue\n",
    "                        log_entry = log.split()\n",
    "                        timestamp = datetime.datetime.strptime(\" \".join(log_entry[:2]), \"%Y%m%d %H:%M:%S.%f\")\n",
    "                        for numa_node in range((len(log_entry) - 2) // len(MEM_METRICS)):\n",
    "                            for (i, metric) in enumerate(MEM_METRICS):\n",
    "                                mem[\"node_name\"].append(node_name)\n",
    "                                mem[\"numa_node\"].append(numa_node)\n",
    "                                mem[\"timestamp\"].append(timestamp)\n",
    "                                mem[\"metric\"].append(metric)\n",
    "                                mem[\"value\"].append(float(log_entry[i + 2 + numa_node * len(MEM_METRICS)]))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "mem = pd.DataFrame.from_dict(mem)\n",
    "min_timestamp = mem[\"timestamp\"].min()\n",
    "mem[\"time\"] = mem.apply(lambda r: (r[\"timestamp\"] - min_timestamp).total_seconds(), axis=1)\n",
    "mem[\"window\"] = mem.apply(lambda r: int(r[\"time\"]), axis=1)\n",
    "mem[\"fg_window\"] = mem.apply(lambda r: int(r[\"time\"] * 1000) // COLLECTL_MEM_FG_WINDOW_SIZE, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory utilization of each node (1-second window)\n",
    "fig = plt.figure(figsize=(12, len(node_names) * 6))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = mem[(mem[\"node_name\"] == node_name) & (mem[\"metric\"] == COLLECTL_MEM_METRIC)]\n",
    "    df = df.groupby([\"window\", \"numa_node\"])[\"value\"].agg(COLLECTL_MEM_AGGREGATION_FUNC)\n",
    "    df = df.reindex([(i, j) for i in range(mem[\"window\"].max() + 1) for j in range(mem[\"numa_node\"].max() + 1)],\n",
    "        fill_value=0)\n",
    "    df = df.unstack()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((0, df.index.max()))\n",
    "    ax.set_ylim((0, df.values.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\", title=\"%s - Memory Utilization (1-second window)\" % node_name, xlabel=\"Time (seconds)\",\n",
    "        ylabel=\"%s(%s)\" % (COLLECTL_MEM_AGGREGATION_FUNC, COLLECTL_MEM_METRIC), grid=True,\n",
    "        xticks=range(0, df.index.max() + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory utilization of each node (fine-grained window)\n",
    "fig = plt.figure(figsize=(12, len(node_names) * 6))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = mem[(mem[\"node_name\"] == node_name) & (mem[\"metric\"] == COLLECTL_MEM_METRIC)]\n",
    "    df = df.groupby([\"fg_window\", \"numa_node\"])[\"value\"].agg(COLLECTL_MEM_AGGREGATION_FUNC)\n",
    "    df = df.reindex([(i, j) for i in range(mem[\"fg_window\"].max() + 1) for j in range(mem[\"numa_node\"].max() + 1)],\n",
    "        fill_value=0)\n",
    "    df = df.unstack()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((0, df.index.max()))\n",
    "    ax.set_ylim((0, df.values.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\",\n",
    "        title=\"%s - Memory Utilization (%s-ms window)\" % (node_name, COLLECTL_MEM_FG_WINDOW_SIZE),\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"%s(%s)\" % (COLLECTL_MEM_AGGREGATION_FUNC, COLLECTL_MEM_METRIC), grid=True,\n",
    "        xticks=range(0, df.index.max() + 1, 60 * (1000 // COLLECTL_MEM_FG_WINDOW_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs\n",
    "DSK_METRICS = [\"reads\", \"rmerge\", \"rkbytes\", \"waitr\", \"writes\", \"wmerge\", \"wkbytes\", \"waitw\", \"request\",\n",
    "    \"quelen\", \"wait\", \"svctim\", \"util\"]\n",
    "dsk = {\"node_name\": [], \"dsk_no\": [], \"timestamp\": [], \"metric\": [], \"value\": []}\n",
    "for node_name in node_names:\n",
    "    tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name, \"collectl.tar.gz\")\n",
    "    with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "        for filename in tar.getnames():\n",
    "            if filename.endswith(\".dsk.gz\"):\n",
    "                with gzip.open(tar.extractfile(filename), \"rt\") as dsk_log_file:\n",
    "                    for log in dsk_log_file:\n",
    "                        if log[0] == '#':\n",
    "                            # Skip comments.\n",
    "                            continue\n",
    "                        log_entry = log.split()\n",
    "                        timestamp = datetime.datetime.strptime(\" \".join(log_entry[:2]), \"%Y%m%d %H:%M:%S.%f\")\n",
    "                        for dsk_no in range((len(log_entry) - 2) // (len(DSK_METRICS) + 1)):\n",
    "                            for (i, metric) in enumerate(DSK_METRICS):\n",
    "                                dsk[\"node_name\"].append(node_name)\n",
    "                                dsk[\"dsk_no\"].append(dsk_no)\n",
    "                                dsk[\"timestamp\"].append(timestamp)\n",
    "                                dsk[\"metric\"].append(metric)\n",
    "                                dsk[\"value\"].append(float(log_entry[i + 3 + dsk_no * (len(DSK_METRICS) + 1)]))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "dsk = pd.DataFrame.from_dict(dsk)\n",
    "min_timestamp = dsk[\"timestamp\"].min()\n",
    "dsk[\"time\"] = dsk.apply(lambda r: (r[\"timestamp\"] - min_timestamp).total_seconds(), axis=1)\n",
    "dsk[\"window\"] = dsk.apply(lambda r: int(r[\"time\"]), axis=1)\n",
    "dsk[\"fg_window\"] = dsk.apply(lambda r: int(r[\"time\"] * 1000) // COLLECTL_DSK_FG_WINDOW_SIZE, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot disk I/O utilization of each node (1-second window)\n",
    "fig = plt.figure(figsize=(12, len(node_names) * 6))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = dsk[(dsk[\"node_name\"] == node_name) & (dsk[\"metric\"] == COLLECTL_DSK_METRIC)]\n",
    "    df = df.groupby([\"window\", \"dsk_no\"])[\"value\"].agg(COLLECTL_DSK_AGGREGATION_FUNC)\n",
    "    df = df.reindex([(i, j) for i in range(dsk[\"window\"].max() + 1) for j in range(dsk[\"dsk_no\"].max() + 1)],\n",
    "        fill_value=0)\n",
    "    df = df.unstack()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((0, df.index.max()))\n",
    "    ax.set_ylim((0, df.values.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\", title=\"%s - Disk I/O Utilization (1-second window)\" % node_name,\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"%s(%s) (%%)\" % (COLLECTL_DSK_AGGREGATION_FUNC, COLLECTL_DSK_METRIC),\n",
    "        grid=True, xticks=range(0, df.index.max() + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot disk I/O utilization of each node (fine-grained window)\n",
    "fig = plt.figure(figsize=(12, len(node_names) * 6))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = dsk[(dsk[\"node_name\"] == node_name) & (dsk[\"metric\"] == COLLECTL_DSK_METRIC)]\n",
    "    df = df.groupby([\"fg_window\", \"dsk_no\"])[\"value\"].agg(COLLECTL_DSK_AGGREGATION_FUNC)\n",
    "    df = df.reindex([(i, j) for i in range(dsk[\"fg_window\"].max() + 1) for j in range(dsk[\"dsk_no\"].max() + 1)],\n",
    "        fill_value=0)\n",
    "    df = df.unstack()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((0, df.index.max()))\n",
    "    ax.set_ylim((0, df.values.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\",\n",
    "        title=\"%s - Disk I/O Utilization (%s-ms window)\" % (node_name, COLLECTL_DSK_FG_WINDOW_SIZE),\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"%s(%s) (%%)\" % (COLLECTL_DSK_AGGREGATION_FUNC, COLLECTL_DSK_METRIC),\n",
    "        grid=True, xticks=range(0, df.index.max() + 1, 60))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
